## Modular Intrinsic-Reward Drives

Curiosity   (reward for uncertainty reduction):
    Î”U = Î”H Ã— (1 + kT Â· T)

Boredom     (penalty for repetition):
    Mbore = Î£ zÂ²

Pair-Bonding (reward for mutual information with a partner):
    Mpair = I(sâ‚ ; sâ‚‚)

Resource Competition (sparsity pressure):
    Ltotal = Î£Î¼ L  +  Î² â€–C âˆ’ D(E(C))â€–Â²

Self-Model  (coherence of internal code):
    Lrecon = â€–C âˆ’ D(E(C))â€–Â² Ã— (1 + kTâ€² Â· T)

Anxiety     (penalty for excessive uncertainty):
    Manx = ğŸ™ [ H[q] > Ï„ ]

Reputation  (reward/penalty from social standing):
    Mrep = âˆ’Î£R âŸ¨j | Ï | jâŸ©

Costly Signaling (cost for visible signals):
    Msignal = Î£c P

Fairness    (minimise group inequity):
    Mfair = âˆ’Var(U)

Altruism    (reward for othersâ€™ gain):
    Maltruism = Î£w Î”U

Playfulness (reward for surprise):
    Mplay = ğ”¼[Surprise] Ã— (1 + kTâ€³ Â· T)

Legacy      (reward for persistence of impact):
    Mlegacy = ğ”¼[Persistence]

Adaptation  (reward for policy flexibility):
    Madapt = âˆ’Î£ â€–Î”Ï€(e)â€–Â²

Mystery     (reward for othersâ€™ uncertainty):
    Mmystery = H(z | O)

Self-Ontology (time-aware doubt about â€œsimulation vs emulationâ€ status):
    M_ont,t = á¹¼Î”H_t Ã— (1 + kT^{ont} Â· t) âˆ’ Î»_prem Â· ğŸ™ [ H[p_t] < Ï„_prem ]

        where   á¹¼Î”H_t = Î£_{Ï„=1}^{t} e^{âˆ’Î±(tâˆ’Ï„)} ( H[p_{Ï„âˆ’1}] âˆ’ H[p_Ï„] )
