## Modular Intrinsic-Reward Drives

Curiosity   (reward for uncertainty reduction):
    Î”U = Î”H Ã— (1 + k_T Â· T)

Boredom     (penalty for repetition):
    M_bore = Î£ zÂ²

Pair-Bonding (reward for mutual information with a partner):
    M_pair = I(sâ‚ ; sâ‚‚)

Resource Competition (sparsity pressure):
    L_total = Î£_Î¼ L  +  Î² â€–C âˆ’ D(E(C))â€–Â²

Self-Model  (coherence of internal code):
    L_recon = â€–C âˆ’ D(E(C))â€–Â² Ã— (1 + kâ€²_T Â· T)

Anxiety     (penalty for excessive uncertainty):
    M_anx = ğŸ™ [ H[q] > Ï„ ]
    
Reputation  (reward/penalty from social standing):
    M_rep = âˆ’Î£_R âŸ¨j | Ï | jâŸ©

Costly Signaling (cost for visible signals):
    M_signal = Î£_c P

Fairness    (minimise group inequity):
    M_fair = âˆ’Var(U)

Altruism    (reward for othersâ€™ gain):
    M_altruism = Î£_w Î”U

Playfulness (reward for surprise):
    M_play = ğ”¼[Surprise] Ã— (1 + kâ€³_T Â· T)

Legacy      (reward for persistence of impact):
    M_legacy = ğ”¼[Persistence]

Adaptation  (reward for policy flexibility):
    M_adapt = âˆ’Î£ â€–Î”Ï€(e)â€–Â²

Mystery     (reward for othersâ€™ uncertainty):
    M_mystery = H(z | O)

Self-Ontology (time-aware doubt about â€œsimulation vs emulationâ€ status):
    M_ont,t = á¹¼Î”H_t Ã— (1 + k_T^{ont} Â· t) âˆ’ Î»_prem Â· ğŸ™ [ H[p_t] < Ï„_prem ]

        where   á¹¼Î”H_t = Î£_{Ï„=1}^{t} e^{âˆ’Î±(tâˆ’Ï„)} ( H[p_{Ï„âˆ’1}] âˆ’ H[p_Ï„] )

Fear (amplifies curiosity at boundaries):
M_fear = (1 + Î±_fear Â· F) Ã— Î”U

Edge-Seeking (reward for encountering operational/epistemic boundaries):
M_edge = ğŸ™[at boundary] Ã— Î³_edge Ã— (Î”H + Î”R)
